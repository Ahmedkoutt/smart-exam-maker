import logging
import asyncio
import io
import tempfile
import os
import requests
import fitz  # PyMuPDF
from datetime import datetime
from typing import Dict, List, Optional
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters
)
import google.generativeai as genai
from openai import OpenAI

# ==================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ† ====================
CONFIG = {
    "8230055864:AAEdurZreFC9NmeswGof56vbdw6ydrMkBN0": "Ø¶Ø¹_ØªÙˆÙƒÙ†_Ø¨ÙˆØªÙƒ_Ù‡Ù†Ø§",
    
    # DeepSeek API (Ù…Ø¬Ø§Ù†ÙŠ Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„)
    "sk-d5015cb2f3bb4692a90d16c66269d080": "Ø¶Ø¹_Ù…ÙØªØ§Ø­_deepseek_Ù‡Ù†Ø§",
    "DEEPSEEK_API_URL": "https://api.deepseek.com/v1/chat/completions",
    
    # Google Gemini API (Ù…Ø¬Ø§Ù†ÙŠ Ø¨Ø­Ø¯ÙˆØ¯)
    "AIzaSyDc7RTkTmCcGykCo4JfwluvH8mUXyJzF1o": "Ø¶Ø¹_Ù…ÙØªØ§Ø­_gemini_Ù‡Ù†Ø§",
    
    # OpenAI ChatGPT API (Ù…Ø¯ÙÙˆØ¹)
    "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": "Ø¶Ø¹_Ù…ÙØªØ§Ø­_openai_Ù‡Ù†Ø§",
    
    # OCR API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    "OCR_API_URL": "https://sii3.top/api/OCR.php",
    
    "MAX_PDF_PAGES": 50,  # Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ ØµÙØ­Ø§Øª Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    "MAX_FILE_SIZE": 20 * 1024 * 1024,  # 20MB
}

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ==================== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ====================
class AIModelManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ø«Ù„Ø§Ø«Ø©"""
    
    def __init__(self):
        # Ø¥Ø¹Ø¯Ø§Ø¯ Gemini
        genai.configure(api_key=CONFIG["GEMINI_API_KEY"])
        self.gemini_model = genai.GenerativeModel('gemini-1.5-pro')
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ OpenAI
        self.openai_client = OpenAI(api_key=CONFIG["OPENAI_API_KEY"])
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ DeepSeek
        self.deepseek_headers = {
            "Authorization": f"Bearer {CONFIG['DEEPSEEK_API_KEY']}",
            "Content-Type": "application/json"
        }
    
    async def process_with_gemini(self, text: str, pdf_text: str = None) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini"""
        try:
            prompt = f"""
            Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±Ø³Ù„: {text}
            
            {'='*50}
            {'Ù…Ø­ØªÙˆÙ‰ PDF Ù…Ø±ÙÙ‚:' if pdf_text else ''}
            {pdf_text[:3000] if pdf_text else ''}
            {'='*50}
            
            Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø§ Ù„Ù… ÙŠØ·Ù„Ø¨ Ø®Ù„Ø§Ù Ø°Ù„Ùƒ.
            """
            
            response = self.gemini_model.generate_content(prompt)
            return response.text
        
        except Exception as e:
            logger.error(f"Gemini error: {e}")
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ Gemini: {str(e)}"
    
    async def process_with_chatgpt(self, text: str, pdf_text: str = None) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ChatGPT"""
        try:
            messages = [
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙÙŠØ¯ ØªØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."}
            ]
            
            if pdf_text:
                messages.append({
                    "role": "user", 
                    "content": f"Ù…Ø­ØªÙˆÙ‰ PDF Ù„Ù„ØªØ­Ù„ÙŠÙ„:\n{pdf_text[:3000]}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {text}"
                })
            else:
                messages.append({"role": "user", "content": text})
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
        
        except Exception as e:
            logger.error(f"ChatGPT error: {e}")
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ ChatGPT: {str(e)}"
    
    async def process_with_deepseek(self, text: str, pdf_text: str = None) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DeepSeek"""
        try:
            messages = [
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."},
                {"role": "user", "content": f"{pdf_text}\n\n{text}" if pdf_text else text}
            ]
            
            payload = {
                "model": "deepseek-chat",
                "messages": messages,
                "max_tokens": 2000,
                "temperature": 0.7
            }
            
            response = requests.post(
                CONFIG["DEEPSEEK_API_URL"],
                headers=self.deepseek_headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                return f"âŒ Ø®Ø·Ø£ DeepSeek: {response.status_code}"
        
        except Exception as e:
            logger.error(f"DeepSeek error: {e}")
            return f"âŒ Ø®Ø·Ø£ ÙÙŠ DeepSeek: {str(e)}"
    
    async def generate_pdf_content(self, model: str, topic: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù…Ù„Ù PDF Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
        prompts = {
            "gemini": f"Ø£Ù†Ø´Ø¦ Ù…Ø­ØªÙˆÙ‰ Ù…ØªØ¹Ù…Ù‚ Ø¹Ù†: {topic}\n\nØ§Ù„Ù…Ø­ØªÙˆÙ‰ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¬Ø§Ù‡Ø²Ù‹Ø§ Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PDF Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆÙÙ‚Ø±Ø§Øª Ù…Ù†Ø¸Ù…Ø©.",
            "chatgpt": f"Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ø­ÙˆÙ„: {topic}\n\nØ§Ø¬Ø¹Ù„Ù‡ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„ØªÙ†Ø³ÙŠÙ‚ PDF Ù…Ø¹ Ù‡ÙŠÙƒÙ„ ÙˆØ§Ø¶Ø­.",
            "deepseek": f"Ø£ÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù†: {topic}\n\nØ±ØªØ¨Ù‡Ø§ Ø¨Ø¹Ù†Ø§ÙŠØ© Ù„Ù„Ø·Ø¨Ø§Ø¹Ø© ÙÙŠ Ù…Ù„Ù PDF."
        }
        
        if model == "gemini":
            return await self.process_with_gemini(prompts["gemini"])
        elif model == "chatgpt":
            return await self.process_with_chatgpt(prompts["chatgpt"])
        elif model == "deepseek":
            return await self.process_with_deepseek(prompts["deepseek"])
        
        return ""

class PDFProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„Ù…Ù„ÙØ§Øª PDF"""
    
    @staticmethod
    async def extract_text(pdf_bytes: bytes, max_pages: int = 20) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF"""
        try:
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            text_parts = []
            
            for page_num in range(min(len(doc), max_pages)):
                page = doc.load_page(page_num)
                text = page.get_text()
                text_parts.append(f"=== ØµÙØ­Ø© {page_num + 1} ===\n{text}")
            
            doc.close()
            return "\n\n".join(text_parts)
        
        except Exception as e:
            logger.error(f"PDF extraction error: {e}")
            return ""
    
    @staticmethod
    async def analyze_pdf_structure(pdf_bytes: bytes) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ PDF"""
        try:
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            analysis = {
                "total_pages": len(doc),
                "metadata": doc.metadata,
                "has_images": False,
                "has_toc": False,
                "fonts": set()
            }
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙØ­Ø§Øª
            for page_num in range(min(5, len(doc))):
                page = doc.load_page(page_num)
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙˆØ±
                if page.get_images():
                    analysis["has_images"] = True
                
                # Ø¬Ù…Ø¹ Ø§Ù„Ø®Ø·ÙˆØ·
                fonts = page.get_fonts()
                for font in fonts:
                    analysis["fonts"].add(font[3])
            
            doc.close()
            return analysis
        
        except Exception as e:
            logger.error(f"PDF analysis error: {e}")
            return {}
    
    @staticmethod
    async def create_pdf_from_text(text: str, filename: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù PDF Ù…Ù† Ø§Ù„Ù†Øµ"""
        try:
            # Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… HTML
            html_content = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <style>
                    body {{ font-family: 'Arial', sans-serif; line-height: 1.6; margin: 40px; }}
                    h1 {{ color: #2c3e50; border-bottom: 2px solid #3498db; }}
                    .content {{ text-align: right; direction: rtl; }}
                </style>
            </head>
            <body>
                <div class="content">
                    <h1>Ù…Ø³ØªÙ†Ø¯ Ù…ÙˆÙ„Ø¯ Ù…Ù† Ø§Ù„Ø¨ÙˆØª</h1>
                    <p>{text.replace(chr(10), '<br>')}</p>
                </div>
            </body>
            </html>
            """
            
            # Ø­ÙØ¸ HTML Ù…Ø¤Ù‚ØªÙ‹Ø§
            with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False) as f:
                f.write(html_content)
                html_path = f.name
            
            # ØªØ­ÙˆÙŠÙ„ HTML Ø¥Ù„Ù‰ PDF (ÙŠØªØ·Ù„Ø¨ wkhtmltopdf)
            pdf_path = filename
            os.system(f"wkhtmltopdf {html_path} {pdf_path}")
            
            os.unlink(html_path)
            return pdf_path
        
        except Exception as e:
            logger.error(f"PDF creation error: {e}")
            return ""

# ==================== Ø¥Ø¯Ø§Ø±Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ====================
class UserSession:
    """Ø¥Ø¯Ø§Ø±Ø© Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
    
    def __init__(self):
        self.sessions: Dict[int, Dict] = {}
    
    def get_session(self, user_id: int) -> Dict:
        if user_id not in self.sessions:
            self.sessions[user_id] = {
                "selected_model": "gemini",  # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
                "last_pdf_text": "",
                "last_pdf_analysis": {},
                "conversation_history": []
            }
        return self.sessions[user_id]
    
    def update_model(self, user_id: int, model: str):
        session = self.get_session(user_id)
        session["selected_model"] = model
    
    def save_pdf_text(self, user_id: int, text: str):
        session = self.get_session(user_id)
        session["last_pdf_text"] = text
    
    def get_pdf_text(self, user_id: int) -> str:
        session = self.get_session(user_id)
        return session.get("last_pdf_text", "")

# ==================== Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ====================
class MultiAIBot:
    def __init__(self):
        self.app = None
        self.model_manager = AIModelManager()
        self.pdf_processor = PDFProcessor()
        self.user_sessions = UserSession()
    
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø¨ÙˆØª ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        welcome_text = """
        ğŸ¤– **Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ø¨ÙˆØª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…**
        
        **ğŸ¯ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:**
        â€¢ Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙƒØ§Ù…Ù„Ø© (Ø§Ø³ØªØ®Ø±Ø§Ø¬ØŒ ØªØ­Ù„ÙŠÙ„ØŒ Ø¥Ù†Ø´Ø§Ø¡)
        â€¢ Ø«Ù„Ø§Ø« Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:
          - ğŸ¤– Google Gemini (Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ù‡Ø§Ù…)
          - ğŸ§  DeepSeek (Ù…Ø¬Ø§Ù†ÙŠ ÙˆÙ‚ÙˆÙŠ)
          - ğŸ’¬ ChatGPT-4 (Ø§Ù„Ø£ÙƒØ«Ø± ØªØ·ÙˆØ±Ø§Ù‹)
        
        **ğŸ“Œ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©:**
        /start - Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        /models - Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        /ask - Ø³Ø¤Ø§Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯
        /analyze - ØªØ­Ù„ÙŠÙ„ PDF Ù…ØªÙ‚Ø¯Ù…
        /createpdf - Ø¥Ù†Ø´Ø§Ø¡ PDF Ø¬Ø¯ÙŠØ¯
        /help - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
        
        **ğŸ“¤ Ø£Ø±Ø³Ù„ Ù„ÙŠ Ù…Ù„Ù PDF Ù„Ø£Ø¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„!**
        """
        
        keyboard = [
            [
                InlineKeyboardButton("ğŸ¤– Gemini", callback_data="model_gemini"),
                InlineKeyboardButton("ğŸ§  DeepSeek", callback_data="model_deepseek"),
                InlineKeyboardButton("ğŸ’¬ ChatGPT", callback_data="model_chatgpt")
            ],
            [
                InlineKeyboardButton("ğŸ“Š ØªØ­Ù„ÙŠÙ„ PDF", callback_data="analyze_pdf"),
                InlineKeyboardButton("ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ PDF", callback_data="create_pdf")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            welcome_text,
            parse_mode='Markdown',
            reply_markup=reply_markup
        )
    
    async def show_models(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„Ø§Ø®ØªÙŠØ§Ø±"""
        user_id = update.effective_user.id
        current_model = self.user_sessions.get_session(user_id)["selected_model"]
        
        models_text = f"""
        **ğŸ”„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©:**
        
        ğŸ¤– **Google Gemini** (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ: {'âœ…' if current_model == 'gemini' else 'â˜‘ï¸'})
        - ÙŠØ¯Ø¹Ù… Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ
        - Ù…Ø¬Ø§Ù†ÙŠ Ø¨Ø­Ø¯ÙˆØ¯ Ù…Ø¹Ù‚ÙˆÙ„Ø©
        - Ø³Ø±ÙŠØ¹ ÙˆÙØ¹Ø§Ù„
        
        ğŸ§  **DeepSeek** (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ: {'âœ…' if current_model == 'deepseek' else 'â˜‘ï¸'})
        - Ù…Ø¬Ø§Ù†ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        - ÙŠØ¯Ø¹Ù… Ø³ÙŠØ§Ù‚ Ø·ÙˆÙŠÙ„
        - Ø¬ÙŠØ¯ Ù„Ù„ØªØ­Ù„ÙŠÙ„
        
        ğŸ’¬ **ChatGPT-4** (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ: {'âœ…' if current_model == 'chatgpt' else 'â˜‘ï¸'})
        - Ø§Ù„Ø£ÙƒØ«Ø± ØªØ·ÙˆØ±Ø§Ù‹
        - ÙŠØ­ØªØ§Ø¬ Ø§Ø´ØªØ±Ø§Ùƒ Ù…Ø¯ÙÙˆØ¹
        - Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ù‡Ø§Ù…
        
        **Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù…Ù‡Ù…ØªÙƒ:**
        """
        
        keyboard = [
            [
                InlineKeyboardButton("ğŸ¤– Ø§Ø®ØªÙŠØ§Ø± Gemini", callback_data="model_gemini"),
                InlineKeyboardButton("ğŸ§  Ø§Ø®ØªÙŠØ§Ø± DeepSeek", callback_data="model_deepseek"),
                InlineKeyboardButton("ğŸ’¬ Ø§Ø®ØªÙŠØ§Ø± ChatGPT", callback_data="model_chatgpt")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            models_text,
            parse_mode='Markdown',
            reply_markup=reply_markup
        )
    
    async def handle_pdf(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª PDF Ø§Ù„Ù…Ø±Ø³Ù„Ø©"""
        user_id = update.effective_user.id
        
        try:
            await update.message.reply_text("ğŸ“¥ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªÙ„Ø§Ù… ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© PDF...")
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
            file = await update.message.document.get_file()
            file_bytes = io.BytesIO()
            await file.download_to_memory(file_bytes)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
            await update.message.reply_text("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF...")
            extracted_text = await self.pdf_processor.extract_text(file_bytes.getvalue())
            
            if not extracted_text:
                await update.message.reply_text("âŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù")
                return
            
            # Ø­ÙØ¸ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
            self.user_sessions.save_pdf_text(user_id, extracted_text)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡ÙŠÙƒÙ„
            await update.message.reply_text("ğŸ“Š Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ PDF...")
            analysis = await self.pdf_processor.analyze_pdf_structure(file_bytes.getvalue())
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            summary = f"""
            âœ… **ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!**
            
            ğŸ“„ **Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù:**
            â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {analysis.get('total_pages', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}
            â€¢ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±: {'âœ… Ù†Ø¹Ù…' if analysis.get('has_images') else 'âŒ Ù„Ø§'}
            â€¢ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬: {len(extracted_text)} Ø­Ø±Ù
            
            ğŸ’¾ **Ø§Ù„ØªØ®Ø²ÙŠÙ†:**
            â€¢ Ø§Ù„Ù†Øµ Ù…Ø­ÙÙˆØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            â€¢ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø¹ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬
            
            **ğŸ“Œ Ù…Ø§ Ø§Ù„ØªØ§Ù„ÙŠØŸ**
            1. Ø§Ø³ØªØ®Ø¯Ù… /ask Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            2. Ø§Ø³ØªØ®Ø¯Ù… /analyze Ù„ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…
            3. Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ Ù…Ù† /models
            """
            
            keyboard = [
                [
                    InlineKeyboardButton("ğŸ“ ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰", callback_data="ask_with_pdf"),
                    InlineKeyboardButton("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…", callback_data="deep_analyze")
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await update.message.reply_text(
                summary,
                parse_mode='Markdown',
                reply_markup=reply_markup
            )
            
            # Ø¥Ø±Ø³Ø§Ù„ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†Øµ
            preview = extracted_text[:500] + "..." if len(extracted_text) > 500 else extracted_text
            await update.message.reply_text(f"ğŸ“‹ **Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†Øµ:**\n\n{preview}")
        
        except Exception as e:
            logger.error(f"PDF handling error: {e}")
            await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© PDF: {str(e)}")
    
    async def ask_question(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
        user_id = update.effective_user.id
        session = self.user_sessions.get_session(user_id)
        
        if not context.args:
            await update.message.reply_text("âš ï¸ Ø§Ø³ØªØ®Ø¯Ù…: /ask Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§")
            return
        
        question = " ".join(context.args)
        pdf_text = session.get("last_pdf_text", "")
        model = session["selected_model"]
        
        await update.message.reply_text(f"ğŸ¤” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¹ {model.upper()}...")
        
        try:
            if model == "gemini":
                response = await self.model_manager.process_with_gemini(question, pdf_text)
            elif model == "chatgpt":
                response = await self.model_manager.process_with_chatgpt(question, pdf_text)
            elif model == "deepseek":
                response = await self.model_manager.process_with_deepseek(question, pdf_text)
            else:
                response = "âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
            
            # ØªÙ‚Ù„ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø·ÙˆÙŠÙ„Ø©
            if len(response) > 4000:
                response = response[:4000] + "\n\n... (Ø§Ù„Ù†Øµ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹)"
            
            await update.message.reply_text(
                f"ğŸ¤– **Ø¥Ø¬Ø§Ø¨Ø© {model.upper()}:**\n\n{response}",
                parse_mode='Markdown'
            )
        
        except Exception as e:
            logger.error(f"Question processing error: {e}")
            await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")
    
    async def create_pdf_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ø¥Ù†Ø´Ø§Ø¡ PDF Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        user_id = update.effective_user.id
        session = self.user_sessions.get_session(user_id)
        
        if not context.args:
            await update.message.reply_text("âš ï¸ Ø§Ø³ØªØ®Ø¯Ù…: /createpdf Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
            return
        
        topic = " ".join(context.args)
        model = session["selected_model"]
        
        await update.message.reply_text(f"ğŸ“ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø¹Ù† '{topic}' Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {model}...")
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            content = await self.model_manager.generate_pdf_content(model, topic)
            
            if not content:
                await update.message.reply_text("âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
                return
            
            # Ø¥Ù†Ø´Ø§Ø¡ PDF
            filename = f"generated_{user_id}_{int(datetime.now().timestamp())}.pdf"
            await update.message.reply_text("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù PDF...")
            
            pdf_path = await self.pdf_processor.create_pdf_from_text(content, filename)
            
            if os.path.exists(pdf_path):
                with open(pdf_path, 'rb') as f:
                    await update.message.reply_document(
                        document=f,
                        filename=f"Ù…Ø³ØªÙ†Ø¯_{topic[:20]}.pdf",
                        caption=f"ğŸ“„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆÙ„Ø¯ Ø¨ÙˆØ§Ø³Ø·Ø© {model.upper()}"
                    )
                os.remove(pdf_path)
            else:
                await update.message.reply_text("âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù PDF")
        
        except Exception as e:
            logger.error(f"PDF creation error: {e}")
            await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {str(e)}")
    
    async def analyze_pdf(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù…Ù„Ù PDF"""
        user_id = update.effective_user.id
        pdf_text = self.user_sessions.get_pdf_text(user_id)
        
        if not pdf_text:
            await update.message.reply_text("âš ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù…Ù„Ù PDF. Ø£Ø±Ø³Ù„ Ù…Ù„Ù PDF Ø£ÙˆÙ„Ø§Ù‹.")
            return
        
        await update.message.reply_text("ğŸ”¬ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ­Ù„ÙŠÙ„
        session = self.user_sessions.get_session(user_id)
        model = session["selected_model"]
        
        analysis_prompt = f"""
        Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙ†Ø¯ PDF Ø´Ø§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ:
        
        {pdf_text[:3000]}
        
        **Ø§Ø·Ù„Ø¨ Ù…Ù†Ùƒ:**
        1. ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
        2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        3. Ø§Ù‚ØªØ±Ø§Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØªÙ‚Ù†ÙŠØ§Ù‹
        4. ØªÙ‚Ø¯ÙŠÙ… ØªÙ‚ÙŠÙŠÙ… Ø¹Ø§Ù…
        
        Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
        """
        
        try:
            if model == "gemini":
                analysis = await self.model_manager.process_with_gemini(analysis_prompt)
            elif model == "chatgpt":
                analysis = await self.model_manager.process_with_chatgpt(analysis_prompt)
            elif model == "deepseek":
                analysis = await self.model_manager.process_with_deepseek(analysis_prompt)
            else:
                analysis = "âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
            
            await update.message.reply_text(
                f"ğŸ“Š **ØªØ­Ù„ÙŠÙ„ PDF Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {model.upper()}:**\n\n{analysis}",
                parse_mode='Markdown'
            )
        
        except Exception as e:
            logger.error(f"Analysis error: {e}")
            await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")
    
    async def handle_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¶ØºØ·Ø§Øª Ø§Ù„Ø£Ø²Ø±Ø§Ø±"""
        query = update.callback_query
        await query.answer()
        
        user_id = update.effective_user.id
        data = query.data
        
        if data.startswith("model_"):
            model = data.split("_")[1]
            self.user_sessions.update_model(user_id, model)
            await query.edit_message_text(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: **{model.upper()}**", parse_mode='Markdown')
        
        elif data == "ask_with_pdf":
            keyboard = [[InlineKeyboardButton("ğŸ“ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³Ø¤Ø§Ù„", switch_inline_query_current_chat="/ask ")]]
